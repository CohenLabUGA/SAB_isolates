{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdaeac3",
   "metadata": {},
   "source": [
    "# Differential gene expression with DESeq2\n",
    "\n",
    "\n",
    "This notebook with create two of the following\n",
    "1. matrix of significant differentially expressed orf's from the results of the differential expression analysis\n",
    "2. matrix of VSD normalized counts ordered by variance across samples\n",
    "\n",
    "Both of these files will be created for transcript-level data and \"gene-level\" data using only transcripts with Kegg annotations and summing by Kegg annotation. \n",
    "<b>The second method will result in data with rownames as Kegg annotations, meaning each annotation appears once in the matrix. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeabfee",
   "metadata": {},
   "source": [
    "\n",
    "### Prepare environment\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d6982",
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " \n",
    "library('tximport', quietly=T)\n",
    "library('DESeq2',quietly=T)\n",
    "library('ashr',quietly=T)\n",
    "library('tibble',quietly=T)\n",
    "library('tidyverse',quietly=T)\n",
    "library('Glimma',quietly=T)\n",
    "library('RCurl',quietly=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10b8cd6",
   "metadata": {},
   "source": [
    "## DE analysis on all open reading frames (ORFs)\n",
    "1. Read in Salmon Counts\n",
    "----\n",
    "First, the count data from Salmon are read with with the `read.in` function which takes:\n",
    "- a pattern matching all salmon output files\n",
    "- the directory to each salmon file\n",
    "\n",
    "My data were separated into different folders, one for each organism, and the salmon output were placed within each. The pattern and directory can be changed based on file organization scheme. The raw counts are finally read in with `Tximport` specifying that <i>Salmon<i> was used.\n",
    "\n",
    "Next metadata are created for each salmon file using information in the salmon file header. The header has all three metadata categories combined, organism_treatment_replicate, so I extract the column names and use patterns matching each to separate each accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b7d25-9166-4aad-b31a-b6522d94eaf5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#fixing tximport function \n",
    "\n",
    "pattern='[[:alpha:]]+([[:digit:]]{2}|_)(_9[[:alpha:]]|[[:alpha:]]*)'\n",
    "\n",
    "read.in <- function(org){\n",
    "    dir <- paste(\"/work/nclab/lucy/SAB/Assembly/\",org,\"/salmon\",sep='')\n",
    "    files <- file.path(dir,list.files(dir,pattern=\".sf\",recursive=TRUE))\n",
    "    \n",
    "    names(files)=str_extract(files,pattern)\n",
    "    names(files)=str_replace(names(files),'oFe', 'pFe') #correct a sample for 08 from oFe to pFe\n",
    "\n",
    "    if (all(file.exists(files)) == FALSE) {\n",
    "        print(\"ERROR IN FILE NAMES, not all files exist\")\n",
    "        print(paste(\"Directory:\", dir, sep=\"/n\"))\n",
    "        print(paste(\"Files:\", files, sep='/n'))\n",
    "    }\n",
    "    \n",
    "    raw_counts <- tximport(files, type='salmon', txOut = TRUE) \n",
    "}\n",
    "\n",
    "create.metadata=function(org){\n",
    "    dir <- paste(\"/work/nclab/lucy/SAB/Assembly/\",org,\"/salmon\",sep='')\n",
    "    files <- file.path(dir,list.files(dir,pattern=\".sf\",recursive=TRUE))\n",
    "    \n",
    "    id=str_extract(files,pattern)\n",
    "    id=str_replace(id,'oFe', 'pFe')\n",
    "    metadata=data.frame('id'=id,\n",
    "                        'isolate'=org,\n",
    "                        'treatment'=str_extract(id,'[[:alpha:]]+(19|21_9|_back)'),\n",
    "                        'rep'=str_extract(id, 'A|B|C'))\n",
    "    metadata$treatment=str_replace_all(\n",
    "        metadata$treatment,\n",
    "        c('pFe19'='High_Iron', 'pFe21_9'='Low_Iron','add_back'='Add_Back'))\n",
    "    metadata\n",
    "    print(metadata)                    \n",
    "}\n",
    "counts_4=read.in('04')\n",
    "metadata_4=create.metadata('04')\n",
    "\n",
    "counts_8=read.in('08')\n",
    "metadata_8=create.metadata('08')\n",
    "\n",
    "counts_6=read.in('06')\n",
    "metadata_6=create.metadata('06')\n",
    "\n",
    "counts_13=read.in('13')\n",
    "metadata_13=create.metadata('13')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb40913",
   "metadata": {},
   "source": [
    "### 2. Create DeSeq object\n",
    "---------\n",
    "A DESeq2 object must be made to perform the differential expression analysis; this is done with the `dds` function. Since `Tximport` was used to read in the data, I used `DESeqDataSetFromTximport`. The `dds` function will compete a few more tasks, setting the low iron treatment as the point of comparison (this will enable multiple comparisons between treatments), and filtering out ORFs with fewer than 5 counts, here <b>n = lowest # of replicates in any treatment.<b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c648de-7e0c-477f-93ad-70b5d3a52b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dds <- function(raw_counts, metadata, n){\n",
    "    dds <- DESeqDataSetFromTximport( raw_counts,\n",
    "                             colData=metadata,\n",
    "                             design=~treatment)\n",
    "    dds$treatment <- relevel(dds$treatment, ref = \"Low_Iron\")\n",
    "    keep <- rowSums(counts(dds) >=5) >= n #filter out rows with too low expression\n",
    "    print(nrow(dds))\n",
    "    dds <- dds[keep, ]\n",
    "    print(nrow(dds))\n",
    "    dds\n",
    "}\n",
    "\n",
    "dds4 <- dds(counts_4, metadata_4, 2)\n",
    "dds8 <- dds(counts_8, metadata_8, 2)\n",
    "dds6 <- dds(counts_6, metadata_6, 3)\n",
    "dds13 <- dds(counts_13, metadata_13, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8cd7e6-b6e1-4ca4-b466-39ef1abeb7fc",
   "metadata": {},
   "source": [
    "### 3. Run differential expression analysis\n",
    "---\n",
    "Because the low iron treatment was set as the base level, only one differential expression test needs to be run. The results from each comparison (high iron vs low iron and iron amendment vs low iron) can be extracted with `results()` and specifying the contrast, or comparison. `tidy = TRUE` creates a clean dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f311e5d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "estimating size factors\n",
      "\n",
      "using 'avgTxLength' from assays(dds), correcting for library size\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "gene-wise dispersion estimates\n",
      "\n",
      "mean-dispersion relationship\n",
      "\n",
      "final dispersion estimates\n",
      "\n",
      "fitting model and testing\n",
      "\n",
      "estimating size factors\n",
      "\n",
      "using 'avgTxLength' from assays(dds), correcting for library size\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "gene-wise dispersion estimates\n",
      "\n",
      "mean-dispersion relationship\n",
      "\n",
      "final dispersion estimates\n",
      "\n",
      "fitting model and testing\n",
      "\n",
      "estimating size factors\n",
      "\n",
      "using 'avgTxLength' from assays(dds), correcting for library size\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "gene-wise dispersion estimates\n",
      "\n",
      "mean-dispersion relationship\n",
      "\n",
      "final dispersion estimates\n",
      "\n",
      "fitting model and testing\n",
      "\n",
      "estimating size factors\n",
      "\n",
      "using 'avgTxLength' from assays(dds), correcting for library size\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "gene-wise dispersion estimates\n",
      "\n",
      "mean-dispersion relationship\n",
      "\n",
      "final dispersion estimates\n",
      "\n",
      "fitting model and testing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run differential expression test\n",
    "de4 <- DESeq(dds4)\n",
    "de8 <- DESeq(dds8)\n",
    "de6 <- DESeq(dds6)\n",
    "de13 <- DESeq(dds13)\n",
    "\n",
    "# Define contrasts\n",
    "HvL <- c(\"treatment\", \"High_Iron\", \"Low_Iron\")\n",
    "AvL <- c(\"treatment\", \"Add_Back\", \"Low_Iron\")\n",
    "\n",
    "#results from Iron ammendment vs Low Iron\n",
    "AvL4 <- results(de4, contrast=AvL, tidy=TRUE)\n",
    "AvL8 <- results(de8, contrast=AvL, tidy=TRUE)\n",
    "AvL6 <- results(de6, contrast=AvL, tidy=TRUE)\n",
    "AvL13 <- results(de13, contrast=AvL, tidy=TRUE)\n",
    "\n",
    "#results from High Iron vs Low Iron\n",
    "HvL8  <- results(de8, contrast=HvL, tidy=TRUE)\n",
    "HvL6  <- results(de6, contrast=HvL,  tidy=TRUE)\n",
    "HvL13  <- results(de13,contrast=HvL, tidy=TRUE)\n",
    "\n",
    "colnames(AvL4)[1] <- \"orfs\"\n",
    "colnames(AvL8)[1] <- \"orfs\"\n",
    "colnames(AvL6)[1] <- \"orfs\"\n",
    "colnames(AvL13)[1] <- \"orfs\"\n",
    "\n",
    "colnames(HvL8)[1] <- \"orfs\"\n",
    "colnames(HvL6)[1] <- \"orfs\"\n",
    "colnames(HvL13)[1] <- \"orfs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f9cf75-a4b4-4861-8dea-318f89da224a",
   "metadata": {},
   "source": [
    "### 4. Make table for differentially expressed ORFs\n",
    "---\n",
    "Now the results from the test have been extracted, the number and percent of differentially expressed genes (padj < 0.05) can be calculated and written to a csv file. \n",
    "\n",
    "This loop will go through each organism's de dataframe and loop through each contrast to extract the results, like above. Then the number and percent of significantly differentially expressed ORFs will be calculated and added to a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43162d56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "contrast = list('HvL' = c(\"treatment\", \"High_Iron\", \"Low_Iron\"),\n",
    "                'AvL' =c(\"treatment\", \"Add_Back\", \"Low_Iron\"))\n",
    "de_output = data.frame('Contrast'=as.character(), 'Organism'=as.character(), \n",
    "                       'number_de'=as.numeric(), 'percent_de'=as.numeric())\n",
    "organism = list(de4, de8, de6, de13)\n",
    "\n",
    "for (o in organism) {\n",
    "     if (colData(o)[1,2] == colData(de4)[1,2]) {\n",
    "        isolate='C. closterium UGA4'\n",
    "    }else if (colData(o)[1,2] == colData(de8)[1,2]) {\n",
    "        isolate='C. closterium UGA8'\n",
    "    }else if (colData(o)[1,2] == colData(de6)[1,2]) {\n",
    "           isolate='G. oceanica'\n",
    "    }else if (colData(o)[1,2] == colData(de13)[1,2]) {            \n",
    "        isolate='G. huxleyi'}\n",
    "    for (c in contrast) {\n",
    "        if (isolate =='C. closterium UGA4' & c[2]=='High_Iron'){\n",
    "            next\n",
    "        }\n",
    "        de.c = results(o, contrast=c, tidy=TRUE)\n",
    "        de.percent = (nrow(filter(de.c,(padj < 0.05)==T))/nrow(o)*100)\n",
    "        de.num = nrow(filter(de.c,(padj < 0.05) ==T))\n",
    "        deAdd = data.frame('Contrast'= c[2], 'Organism'=isolate, 'number_de'=de.num, 'percent_de'=de.percent)\n",
    "        de_output = rbind(de_output, deAdd)\n",
    "    }\n",
    "              }\n",
    "\n",
    "de_output\n",
    "\n",
    "write.csv(de_output, './de_res_files/de_output.csv', row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f976821",
   "metadata": {},
   "source": [
    "### 2.2 VSD Normalize counts \n",
    "---\n",
    "Order rows by variance across treatment. Top rows will have highest variance in normalized counts between treatments. Save in vsd folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "744d73cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using 'avgTxLength' from assays(dds), correcting for library size\n",
      "\n",
      "using 'avgTxLength' from assays(dds), correcting for library size\n",
      "\n",
      "using 'avgTxLength' from assays(dds), correcting for library size\n",
      "\n",
      "using 'avgTxLength' from assays(dds), correcting for library size\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"saving 04\"\n",
      "[1] \"saving 08\"\n",
      "[1] \"saving 06\"\n",
      "[1] \"saving 13\"\n"
     ]
    }
   ],
   "source": [
    "vsd.norm <- function(dds){\n",
    "    vst(dds,blind=FALSE)\n",
    "    }\n",
    "\n",
    "#full vsd deseq2 objects:\n",
    "vsd4 <- vsd.norm(dds4)\n",
    "vsd8 <- vsd.norm(dds8)\n",
    "vsd6 <- vsd.norm(dds6)\n",
    "vsd13 <- vsd.norm(dds13)\n",
    "\n",
    "## order the df's by decreasing variance. top rows have highest varience between \n",
    "## samples. write dataframe\n",
    "write.vsd <- function(vsd, org){\n",
    "    vsd <- assay(vsd)\n",
    "    vsd_order <- order(rowVars(vsd), decreasing=T)\n",
    "    vsd_new <- vsd[vsd_order, ]\n",
    "    print(paste('saving',org,sep=' '))\n",
    "    vsd_new <- as.data.frame(vsd_new) %>% rownames_to_column(\"orfs\")\n",
    "    write.csv(vsd_new, paste('./vsd_files/', org, \"vsd.csv\", sep=\"\"), row.names=FALSE)\n",
    "}\n",
    "\n",
    "write.vsd(vsd4, \"04\")\n",
    "write.vsd(vsd8, \"08\")\n",
    "write.vsd(vsd6, \"06\")\n",
    "write.vsd(vsd13, \"13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600371d8",
   "metadata": {},
   "source": [
    "## Logfold 2 shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18018ff5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lfc4.AvL <- lfcShrink(de4,  contrast=c(\"treatment\", \"Add_Back\", \"Low_Iron\"), type='ashr')\n",
    "lfc4.AvL <- lfc4.AvL %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc4.AvL, \"./de_res_files/lfc4.AvL.csv\", row.names=F)\n",
    "\n",
    "lfc8.AvL <- lfcShrink(de8, contrast=c(\"treatment\", \"Add_Back\", \"Low_Iron\"), type='ashr')\n",
    "lfc8.AvL <- lfc8.AvL %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc8.AvL, \"./de_res_files/lfc8.AvL.csv\", row.names=F)\n",
    "\n",
    "lfc6.AvL <- lfcShrink(de6, contrast=c(\"treatment\", \"Add_Back\", \"Low_Iron\"), type='ashr')\n",
    "lfc6.AvL <- lfc6.AvL %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc6.AvL, \"./de_res_files/lfc6.AvL.csv\", row.names=F)\n",
    "\n",
    "lfc13.AvL <- lfcShrink(de13,  contrast=c(\"treatment\", \"Add_Back\", \"Low_Iron\"), type='ashr')\n",
    "lfc13.AvL <- lfc13.AvL %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc13.AvL, \"./de_res_files/lfc13.AvL.csv\", row.names=F)\n",
    "\n",
    "lfc8.HvL <- lfcShrink(de8, contrast=c(\"treatment\", \"High_Iron\", \"Low_Iron\"), type='ashr')\n",
    "lfc8.HvL <- lfc8.HvL %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc8.HvL, \"./de_res_files/lfc8.HvL.csv\", row.names=F)\n",
    "\n",
    "lfc6.HvL <- lfcShrink(de6, contrast=c(\"treatment\", \"High_Iron\", \"Low_Iron\"), type='ashr')\n",
    "lfc6.HvL <- lfc6.HvL %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc6.HvL, \"./de_res_files/lfc6.HvL.csv\", row.names=F)\n",
    "\n",
    "lfc13.HvL <- lfcShrink(de13,  contrast=c(\"treatment\", \"High_Iron\", \"Low_Iron\"), type='ashr')\n",
    "lfc13.HvL <- lfc13.HvL %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc13.HvL, \"./de_res_files/lfc13.HvL.csv\", row.names=F)\n",
    "\n",
    "lfc8.AvH <- lfcShrink(de8, contrast=c(\"treatment\", \"Add_Back\", \"High_Iron\"), type='ashr')\n",
    "lfc8.AvH <- lfc8.AvH %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc8.AvH, \"./de_res_files/lfc8.AvH.csv\", row.names=F)\n",
    "\n",
    "lfc6.AvH <- lfcShrink(de6, contrast=c(\"treatment\", \"Add_Back\", \"High_Iron\"), type='ashr')\n",
    "lfc6.AvH <- lfc6.AvH %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc6.AvH, \"./de_res_files/lfc6.AvH.csv\", row.names=F)\n",
    "\n",
    "lfc13.AvH <- lfcShrink(de13,  contrast=c(\"treatment\", \"Add_Back\", \"High_Iron\"), type='ashr')\n",
    "lfc13.AvH <- lfc13.AvH %>% as.data.frame() %>% rownames_to_column(\"orfs\") \n",
    "write.csv(lfc13.AvH, \"./de_res_files/lfc13.AvH.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdbed7d",
   "metadata": {},
   "source": [
    "## 2.4 Subset results tables by significance and save\n",
    "df's made into a list and looped through to order rows by adjusted p value and pull out significant rows. saving both files. Sorting the _res files positive or negative log2fold change will enable me to get the up regulated and down regulated genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "888d9e80",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"contrast  HvL  for  4  not found\"\n",
      "[1] \"contrast  AvH  for  4  not found\"\n"
     ]
    }
   ],
   "source": [
    "df.names <- list()\n",
    "samples <- c('4','8','6','13')\n",
    "contrasts <- c('AvL','HvL','AvH')\n",
    "\n",
    "for (s in samples){\n",
    "    for (c in contrasts){\n",
    "        if (exists(paste(c,s, sep=\"\")) == FALSE){\n",
    "            print(paste('contrast ', c, ' for ', s, ' not found'))\n",
    "            next}\n",
    "        df.names <- append(df.names, paste(s,c,sep=''))\n",
    "    }\n",
    "}\n",
    "\n",
    "res.ls <- list(AvL4, AvL8, AvL6, AvL13, HvL8, HvL6, HvL13, AvH8, AvH6, AvH13)\n",
    "names(res.ls) <- df.names\n",
    "\n",
    "res.ls <- lapply(res.ls, function(df){   #order each df in list by p.value\n",
    "    arrange(df, padj)\n",
    "})\n",
    "\n",
    "#save each df ordered by p.value\n",
    "walk2(res.ls, paste0(\"./de_res_files/\", names(res.ls), \"_res.csv\", sep=\"\"), write.csv,row.names=F)\n",
    "\n",
    "res.ls.sig <- lapply(res.ls, function(df){   #pull out significant DE's\n",
    "    filter(df, padj<=0.05)\n",
    "})\n",
    "\n",
    "#save significant de's for each df\n",
    "walk2(res.ls.sig, paste0(\"./de_res_files/\", names(res.ls), \"sig_res.csv\", sep=\"\"), write.csv,row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8645be",
   "metadata": {},
   "source": [
    "# Now repeat steps but summarize to 'kegg gene level'\n",
    "## 1. Make df of raw counts which are summed to kegg level.\n",
    "#### Read in the list of ORF-to-Ko's for each sample \n",
    "This list repeates orfs when multiple ko's were assigned to a single orf by eggnog. Using the 'orf' column from the organism specific ko list, we want to map the counts to each row of the orf-to-ko list. This will automatically repeat the counts for each repeated orf in the list and allow us to sum orfs with matching ko's later. \n",
    "\n",
    "<b/> Remember, not all rows from the counts table will have a ko assigned and thus will not appear in the orf-to-ko list. Additionally, not all orfs annotated by eggnog were counted by salmon. Thus we must remove any rows from the orf-to-ko table for which orfs are not found </b>\n",
    "\n",
    "Because some orfs had multiple ko assignments the merging relationship will be many-to-one, many orf-ko rows matching to one counts row. \"Each row in x (orf-to-ko list) matches at most 1 row in y (counts table).\"\n",
    "\n",
    "Once the two tables are merged, we can group by ko_id and sum counts which have the same ko_id. The result is a new raw counts table (matrix) which we can used in deseq. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0702e78",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \" # unique ko_ids should equal number rows of ko-summed counts.\"\n",
      "[1] \"# unique ko_ids = \"\n",
      "[1] 4243\n",
      "[1] \" and # ko-summed counts = \"\n",
      "[1] 4243\n",
      "[1] \" # unique ko_ids should equal number rows of ko-summed counts.\"\n",
      "[1] \"# unique ko_ids = \"\n",
      "[1] 4436\n",
      "[1] \" and # ko-summed counts = \"\n",
      "[1] 4436\n",
      "[1] \" # unique ko_ids should equal number rows of ko-summed counts.\"\n",
      "[1] \"# unique ko_ids = \"\n",
      "[1] 5374\n",
      "[1] \" and # ko-summed counts = \"\n",
      "[1] 5374\n",
      "[1] \" # unique ko_ids should equal number rows of ko-summed counts.\"\n",
      "[1] \"# unique ko_ids = \"\n",
      "[1] 5270\n",
      "[1] \" and # ko-summed counts = \"\n",
      "[1] 5270\n"
     ]
    }
   ],
   "source": [
    "ko.def=read.csv('../kegg_names/ko_def.csv')\n",
    "sum.kegg <- function(org, counts.raw){\n",
    "    ko_df= read.csv(paste('../kegg_names/ko', org,'_ls.csv', sep=''))\n",
    "    #ko_df = organsim-specific orf-to-ko list\n",
    "    ko_df <- select(ko_df, c('orfs', 'ko_id'))\n",
    "    \n",
    "    # make raw counts matrix into a tibble\n",
    "    counts <- as_tibble(counts.raw$counts, rownames = \"orfs\")\n",
    "    \n",
    "    # remove orfs that eggnog annotated but salmon did not count\n",
    "    ko <- filter(ko_df, (ko_df$orfs %in% counts$orfs)==TRUE)\n",
    "    \n",
    "    # remove orfs that did not have a matching kegg annotation\n",
    "    #counts.ko <- filter(counts, (counts$orfs%in%ko_df$orfs)==TRUE)\n",
    "\n",
    "    \n",
    "    # merge the two, so orfs and thier counts are repeated when they match to multiple ko's\n",
    "    b <- left_join(x=ko, y=counts, by='orfs', relationship=\"many-to-one\")\n",
    "    if(all(ko$orfs%in% counts$orfs)==FALSE){\n",
    "        print(paste(\"ERROR: merged counts and ko_ids should be the same length as \n",
    "                    the ko_id df length of merged counts is \", nrow(b), \" and ko_ids is: \", \n",
    "                    nrow(ko), sep=''))\n",
    "    }\n",
    "\n",
    "    #group by ko_id and sum counts for each ko_id\n",
    "    b <- b %>% select(!orfs) %>% \n",
    "        group_by(ko_id) %>% \n",
    "        summarize(across(everything(), sum)) %>%\n",
    "        column_to_rownames(\"ko_id\") %>% \n",
    "        as.matrix\n",
    "    \n",
    "    mode(b) <- 'integer'\n",
    "    print(' # unique ko_ids should equal number rows of ko-summed counts.')\n",
    "    print('# unique ko_ids = ')\n",
    "    print(length(unique(ko$ko_id)))\n",
    "    print(' and # ko-summed counts = ')\n",
    "    print(nrow(b))\n",
    "    b\n",
    "    }\n",
    "\n",
    "kcounts_4 <- sum.kegg('4', counts_4)\n",
    "kcounts_8 <- sum.kegg('8', counts_8)\n",
    "kcounts_6 <- sum.kegg('6', counts_6)\n",
    "kcounts_13 <- sum.kegg('13', counts_13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae074186",
   "metadata": {},
   "source": [
    "## 2. Run DeSeq2 on kegg-summed counts\n",
    "Using DESeqDataSetFromMatrix, read in summed counts matrix.\n",
    "\n",
    "Next, add the ko name and symbol to the metadata for each deseq object. Run the DE and VST normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e23ed91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in DESeqDataSet(se, design = design, ignoreRank):\n",
      "“some variables in design formula are characters, converting to factors”\n",
      "Warning message in DESeqDataSet(se, design = design, ignoreRank):\n",
      "“some variables in design formula are characters, converting to factors”\n",
      "Warning message in DESeqDataSet(se, design = design, ignoreRank):\n",
      "“some variables in design formula are characters, converting to factors”\n",
      "Warning message in DESeqDataSet(se, design = design, ignoreRank):\n",
      "“some variables in design formula are characters, converting to factors”\n",
      "estimating size factors\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "gene-wise dispersion estimates\n",
      "\n",
      "mean-dispersion relationship\n",
      "\n",
      "final dispersion estimates\n",
      "\n",
      "fitting model and testing\n",
      "\n",
      "estimating size factors\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "gene-wise dispersion estimates\n",
      "\n",
      "mean-dispersion relationship\n",
      "\n",
      "final dispersion estimates\n",
      "\n",
      "fitting model and testing\n",
      "\n",
      "estimating size factors\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "gene-wise dispersion estimates\n",
      "\n",
      "mean-dispersion relationship\n",
      "\n",
      "final dispersion estimates\n",
      "\n",
      "fitting model and testing\n",
      "\n",
      "estimating size factors\n",
      "\n",
      "estimating dispersions\n",
      "\n",
      "gene-wise dispersion estimates\n",
      "\n",
      "mean-dispersion relationship\n",
      "\n",
      "final dispersion estimates\n",
      "\n",
      "fitting model and testing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## create deseq object from matrix\n",
    "k.dds <- function(k.counts, metadata,n){\n",
    "    #n = lowest number of reps in any treatment\n",
    "   dds <-  DESeqDataSetFromMatrix(\n",
    "       countData = k.counts, \n",
    "       colData = metadata, \n",
    "       design=~treatment)\n",
    "    dds$treatment <- relevel(dds$treatment, ref = \"Low_Iron\")\n",
    "    keep <- rowSums(counts(dds) >=10) >= n #filter out rows with too low expression\n",
    "    dds <- dds[keep, ]\n",
    "    dds}\n",
    "\n",
    "k.dds4 <- k.dds(kcounts_4, metadata_4, 2)\n",
    "k.dds8 <- k.dds(kcounts_8, metadata_8, 2)\n",
    "k.dds6 <- k.dds(kcounts_6, metadata_6, 3)\n",
    "k.dds13 <- k.dds(kcounts_13, metadata_13, 3)\n",
    "\n",
    "add.rowData <- function(dds, ko_def){\n",
    "    d <- data.frame('ko_id'= rownames(dds))\n",
    "        #filter ko's which are present in the dds df\n",
    "    v <- ko_def[(ko_def$ko_id%in%d$ko_id)==TRUE, c('ko_id', 'symbol', 'name')]\n",
    "        #because counts are summed by ko_id, I need to take only the unique ko's from anno\n",
    "    anno <- distinct(v)\n",
    "    all(rownames(dds)==anno$ko_id)\n",
    "    #reorder annotation table to same row order as dds\n",
    "    anno <- anno[match(rownames(dds), anno$ko_id),]\n",
    "    all(rownames(dds)==anno$ko_id)\n",
    "\n",
    "    mcols(dds) <- cbind(mcols(dds), anno)\n",
    "    print(mcols(dds))\n",
    "}\n",
    "\n",
    "#mcols(k.dds4) <- add.rowData(k.dds4, ko4_def)\n",
    "#mcols(k.dds8) <- add.rowData(k.dds8, ko8_def)\n",
    "#mcols(k.dds6) <- add.rowData(k.dds6, ko6_def)\n",
    "#mcols(k.dds13) <- add.rowData(k.dds13, ko13_def)\n",
    "#mcols(k.dds13)\n",
    "    \n",
    "## vsd normalize and save ordered by variance\n",
    "vsd.norm <- function(dds){\n",
    "    varianceStabilizingTransformation(dds,blind=FALSE)\n",
    "    }\n",
    "k.vsd4 <- vsd.norm(k.dds4)\n",
    "k.vsd8 <- vsd.norm(k.dds8)\n",
    "k.vsd6 <- vsd.norm(k.dds6)\n",
    "k.vsd13 <- vsd.norm(k.dds13)\n",
    "#k.vsd4 <- varianceStabilizingTransformation(k.dds4,blind = FALSE)\n",
    "write.vsd.k <- function(vsd, org){\n",
    "    vsd <- assay(vsd)\n",
    "    vsd_order <- order(rowVars(vsd), decreasing=T)\n",
    "    vsd_new <- vsd[vsd_order, ]\n",
    "    write.csv(vsd_new, paste('./vsd_files/', org, \"vsd.k.csv\", sep=\"\"))\n",
    "}\n",
    "\n",
    "write.vsd.k(k.vsd4, '04')\n",
    "write.vsd.k(k.vsd8, '08')\n",
    "write.vsd.k(k.vsd6, '06')\n",
    "write.vsd.k(k.vsd13, '13')\n",
    "\n",
    "## run differential expression analysis\n",
    "de4.k <- DESeq(k.dds4)\n",
    "de8.k <- DESeq(k.dds8)\n",
    "de6.k <- DESeq(k.dds6)\n",
    "de13.k <- DESeq(k.dds13)\n",
    "\n",
    "#extract results\n",
    "HvL <- c(\"treatment\", \"High_Iron\", \"Low_Iron\")\n",
    "AvL <- c(\"treatment\", \"Add_Back\", \"Low_Iron\")\n",
    "AvH <- c(\"treatment\", \"Add_Back\", \"High_Iron\")\n",
    "\n",
    "#results from Low Iron vs Iron ammendment\n",
    "AvL4.k <- results(de4.k, contrast=AvL, tidy=TRUE)\n",
    "AvL8.k <- results(de8.k, contrast=AvL, tidy=T)\n",
    "AvL6.k <- results(de6.k, contrast=AvL, tidy=TRUE)\n",
    "AvL13.k <- results(de13.k, contrast=AvL, tidy=TRUE)\n",
    "\n",
    "#results from Low Iron vs Iron ammendment\n",
    "AvL4.k <- results(de4.k, contrast=AvL, tidy=TRUE)\n",
    "AvL8.k <- results(de8.k, contrast=AvL, tidy=T)\n",
    "AvL6.k <- results(de6.k, contrast=AvL, tidy=TRUE)\n",
    "AvL13.k <- results(de13.k, contrast=AvL, tidy=TRUE)\n",
    "\n",
    "#results from High Iron vs Low Iron\n",
    "HvL8.k  <- results(de8.k, contrast=HvL, tidy=TRUE)\n",
    "HvL6.k  <- results(de6.k, contrast=HvL,  tidy=TRUE)\n",
    "HvL13.k  <- results(de13.k,contrast=HvL, tidy=TRUE)\n",
    "\n",
    "#results from High Iron vs Iron ammendment\n",
    "AvH8.k  <- results(de8.k, contrast=AvH, tidy=TRUE)\n",
    "AvH6.k  <- results(de6.k, contrast=AvH,  tidy=TRUE)\n",
    "AvH13.k  <- results(de13.k, contrast=AvH, tidy=TRUE)\n",
    "\n",
    "#save deseq results\n",
    "\n",
    "AvL4.k %>% na.omit() %>% write.csv('./de_res_files/AvL4.k.csv', row.names=F)\n",
    "AvL8.k%>% na.omit() %>% write.csv('./de_res_files/AvL8.k.csv', row.names=F)\n",
    "AvL6.k %>% na.omit() %>% write.csv('./de_res_files/AvL6.k.csv', row.names=F)\n",
    "AvL13.k %>% na.omit() %>% write.csv('./de_res_files/AvL13.k.csv', row.names=F)\n",
    "\n",
    "AvH8.k %>% na.omit() %>% write.csv('./de_res_files/AvH8.k.csv', row.names=F)\n",
    "AvH6.k %>% na.omit() %>% write.csv('./de_res_files/AvH6.k.csv', row.names=F)\n",
    "AvH13.k %>% na.omit() %>% write.csv('./de_res_files/AvH13.k.csv', row.names=F)\n",
    "\n",
    "HvL8.k %>% na.omit() %>% write.csv('./de_res_files/HvL8.k.csv', row.names=F)\n",
    "HvL6.k %>% na.omit() %>% write.csv('./de_res_files/HvL6.k.csv', row.names=F)\n",
    "HvL13.k %>% na.omit() %>% write.csv('./de_res_files/HvL13.k.csv', row.names=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "628b0472",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 4 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Organism</th><th scope=col>Iron.amendment.vs.low.iron</th><th scope=col>High.iron.vs.low.iron</th><th scope=col>Iron.amendment.vs.high.iron</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>C. closterium 4</td><td> 206</td><td>NA  </td><td>NA </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>C. closterium 8</td><td> 830</td><td>300 </td><td>947</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>G. oceanica    </td><td>1291</td><td>1381</td><td>221</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>G. huxleyi     </td><td>1154</td><td>1132</td><td>396</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 4 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Organism & Iron.amendment.vs.low.iron & High.iron.vs.low.iron & Iron.amendment.vs.high.iron\\\\\n",
       "  & <chr> & <int> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & C. closterium 4 &  206 & NA   & NA \\\\\n",
       "\t2 & C. closterium 8 &  830 & 300  & 947\\\\\n",
       "\t3 & G. oceanica     & 1291 & 1381 & 221\\\\\n",
       "\t4 & G. huxleyi      & 1154 & 1132 & 396\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 4 × 4\n",
       "\n",
       "| <!--/--> | Organism &lt;chr&gt; | Iron.amendment.vs.low.iron &lt;int&gt; | High.iron.vs.low.iron &lt;chr&gt; | Iron.amendment.vs.high.iron &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | C. closterium 4 |  206 | NA   | NA  |\n",
       "| 2 | C. closterium 8 |  830 | 300  | 947 |\n",
       "| 3 | G. oceanica     | 1291 | 1381 | 221 |\n",
       "| 4 | G. huxleyi      | 1154 | 1132 | 396 |\n",
       "\n"
      ],
      "text/plain": [
       "  Organism        Iron.amendment.vs.low.iron High.iron.vs.low.iron\n",
       "1 C. closterium 4  206                       NA                   \n",
       "2 C. closterium 8  830                       300                  \n",
       "3 G. oceanica     1291                       1381                 \n",
       "4 G. huxleyi      1154                       1132                 \n",
       "  Iron.amendment.vs.high.iron\n",
       "1 NA                         \n",
       "2 947                        \n",
       "3 221                        \n",
       "4 396                        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how many DE's per treatment-sample?\n",
    "\n",
    "avl4.perc.k=(nrow(filter(AvL4.k,(padj < 0.05)==T))/nrow(de4.k))*100\n",
    "avl4.k=nrow(filter(AvL4.k,(padj < 0.05)==T))\n",
    "\n",
    "avl8.perc.k=(nrow(filter(AvL8.k,(padj < 0.05)==T))/nrow(de8.k))*100\n",
    "avl8.k=nrow(filter(AvL8.k,(padj < 0.05)==T))\n",
    "\n",
    "avl6.perc.k=(nrow(filter(AvL6.k,(padj < 0.05)==T))/nrow(de6.k))*100\n",
    "avl6.k=nrow(filter(AvL6.k,(padj < 0.05)==T))\n",
    "\n",
    "avl13.perc.k=(nrow(filter(AvL13.k,(padj < 0.05)==T))/nrow(de13.k))*100\n",
    "avl13.k=nrow(filter(AvL13.k,(padj < 0.05)==T))\n",
    "\n",
    "\n",
    "hvl8.perc.k=(nrow(filter(HvL8.k,(padj < 0.05)==T))/nrow(de8.k))*100\n",
    "hvl8.k=nrow(filter(HvL8.k,(padj < 0.05)==T))\n",
    "\n",
    "hvl6.perc.k=(nrow(filter(HvL6.k,(padj < 0.05)==T))/nrow(de6.k))*100\n",
    "hvl6.k=nrow(filter(HvL6.k,(padj < 0.05)==T))\n",
    "\n",
    "hvl13.perc.k=(nrow(filter(HvL13.k,(padj < 0.05)==T))/nrow(de13.k))*100\n",
    "hvl13.k=nrow(filter(HvL13.k,(padj < 0.05)==T))\n",
    "\n",
    "\n",
    "avh8.perc.k=(nrow(filter(AvH8.k,(padj < 0.05)==T))/nrow(de8.k))*100\n",
    "avh8.k=nrow(filter(AvH8.k,(padj < 0.05)==T))\n",
    "\n",
    "avh6.perc.k=(nrow(filter(AvH6.k,(padj < 0.05)==T))/nrow(de6.k))*100\n",
    "avh6.k=nrow(filter(AvH6.k,(padj < 0.05)==T))\n",
    "\n",
    "avh13.perc.k=(nrow(filter(AvH13.k,(padj < 0.05)==T))/nrow(de13.k))*100\n",
    "avh13.k=nrow(filter(AvH13.k,(padj < 0.05)==T))\n",
    "\n",
    "de_ko_output = data.frame('Organism'=c('C. closterium 4', 'C. closterium 8', 'G. oceanica', 'G. huxleyi'),\n",
    "                       'Iron amendment vs low iron'=c(avl4.k,avl8.k,avl6.k,avl13.k),\n",
    "                       'High iron vs low iron'=c('NA', hvl8.k,hvl6.k,hvl13.k),\n",
    "                       'Iron amendment vs high iron'=c('NA',avh8.k,avh6.k,avh13.k))\n",
    "\n",
    "de_ko_output_perc = data.frame('Organism'=c('C. closterium 4', 'C. closterium 8', 'G. oceanica', 'G. huxleyi'),\n",
    "                       'Iron amendment vs low iron'=c(avl4.perc.k,avl8.perc.k,avl6.perc.k,avl13.perc.k),\n",
    "                       'High iron vs low iron'=c('NA', hvl8.perc.k,hvl6.perc.k,hvl13.perc.k),\n",
    "                       'Iron amendment vs high iron'=c('NA',avh8.perc.k,avh6.perc.k,avh13.perc.k)) \n",
    "\n",
    "write.csv(de_ko_output, './de_res_files/de_ko_output.csv', row.names=F)\n",
    "write.csv(de_ko_output_perc, './de_res_files/de_ko_output_perc.csv', row.names=F)\n",
    "\n",
    "head(de_ko_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ec925b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“\u001b[1m\u001b[22mExpected 2 pieces. Missing pieces filled with `NA` in 17 rows [1, 2, 3, 5, 7, 8, 9, 10, 13, 17, 22, 24,\n",
      "26, 27, 28, 29, 30].”\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22mExpected 2 pieces. Missing pieces filled with `NA` in 15 rows [2, 3, 4, 8, 9, 11, 12, 14, 15, 16, 20, 24,\n",
      "26, 29, 30].”\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22mExpected 2 pieces. Missing pieces filled with `NA` in 14 rows [1, 4, 5, 6, 7, 8, 11, 12, 20, 21, 22, 27,\n",
      "29, 30].”\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22mExpected 2 pieces. Missing pieces filled with `NA` in 18 rows [1, 3, 5, 6, 7, 10, 11, 12, 15, 17, 18, 20,\n",
      "21, 22, 23, 24, 26, 29].”\n"
     ]
    }
   ],
   "source": [
    "#Save info for top 30 VSD normalized orfs with highest variance across samples\n",
    "\n",
    "top30vsd.info <- function(k.vsd, ko_def, org){\n",
    "    #order vsd matrix by variance across samples\n",
    "    vsd <- assay(k.vsd)\n",
    "    var_order <- order(rowVars(vsd), decreasing=T)\n",
    "    vsd_new <- vsd[var_order, ]\n",
    "    vsd_new <- as.data.frame(vsd_new) %>% rownames_to_column(\"ko_id\") \n",
    "    #select top 30 orfs, these have the highest variance\n",
    "    vsd30 <- vsd_new[1:30,]\n",
    "    #merge with name and info for ko id and create seperate column of enzyme info\n",
    "    vsd30 <- left_join(vsd30, ko.def, by = 'ko_id') %>% select('ko_id', 'symbol', 'name')\n",
    "    vsd30 <- vsd30 %>% separate(name, c('name', 'enzyme'), \"\\\\[EC:\")  \n",
    "    vsd30$enzyme <- str_replace(vsd30$enzyme, \"\\\\]\", \"\")\n",
    "    vsd30\n",
    "    write.csv(vsd30, paste(\"./vsd_files/vsd.30.\", org, \".csv\", sep=''), row.names=F)\n",
    "}\n",
    "\n",
    "top30vsd.info(k.vsd4, ko4_def, \"4\")\n",
    "top30vsd.info(k.vsd8, ko8_def, \"8\")\n",
    "top30vsd.info(k.vsd6, ko6_def, \"6\")\n",
    "top30vsd.info(k.vsd13, ko13_def, \"13\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f4ce13",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n",
      "using 'ashr' for LFC shrinkage. If used in published research, please cite:\n",
      "    Stephens, M. (2016) False discovery rates: a new deal. Biostatistics, 18:2.\n",
      "    https://doi.org/10.1093/biostatistics/kxw041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lfc4.k.AvL <- lfcShrink(de4.k,  contrast=c(\"treatment\", \"Add_Back\", \"Low_Iron\"), type='ashr')\n",
    "lfc4.k.AvL <- lfc4.k.AvL %>% as.data.frame() %>% rownames_to_column(\"ko_id\") \n",
    "lfc8.k.AvL <- lfcShrink(de8.k, contrast=c(\"treatment\", \"Add_Back\", \"Low_Iron\"), type='ashr')\n",
    "lfc8.k.AvL <- lfc8.k.AvL %>% as.data.frame() %>% rownames_to_column(\"ko_id\") \n",
    "lfc6.k.AvL <- lfcShrink(de6.k, contrast=c(\"treatment\", \"Add_Back\", \"Low_Iron\"), type='ashr')\n",
    "lfc6.k.AvL <- lfc6.k.AvL %>% as.data.frame() %>% rownames_to_column(\"ko_id\") \n",
    "lfc13.k.AvL <- lfcShrink(de13.k,  contrast=c(\"treatment\", \"Add_Back\", \"Low_Iron\"), type='ashr')\n",
    "lfc13.k.AvL <- lfc13.k.AvL %>% as.data.frame() %>% rownames_to_column(\"ko_id\") \n",
    "\n",
    "\n",
    "lfc8.k.HvL <- lfcShrink(de8.k, contrast=c(\"treatment\", \"High_Iron\", \"Low_Iron\"), type='ashr')\n",
    "lfc8.k.HvL <- lfc8.k.HvL %>% as.data.frame() %>% rownames_to_column(\"ko_id\") \n",
    "lfc6.k.HvL <- lfcShrink(de6.k, contrast=c(\"treatment\", \"High_Iron\", \"Low_Iron\"), type='ashr')\n",
    "lfc6.k.HvL <- lfc6.k.HvL %>% as.data.frame() %>% rownames_to_column(\"ko_id\") \n",
    "lfc13.k.HvL <- lfcShrink(de13.k,  contrast=c(\"treatment\", \"High_Iron\", \"Low_Iron\"), type='ashr')\n",
    "lfc13.k.HvL <- lfc13.k.HvL %>% as.data.frame() %>% rownames_to_column(\"ko_id\") \n",
    "\n",
    "lfc8.k.AvH <- lfcShrink(de8.k, contrast=c(\"treatment\", \"Add_Back\", \"High_Iron\"), type='ashr')\n",
    "lfc8.k.AvH <- lfc8.k.AvH %>% as.data.frame() %>% rownames_to_column(\"ko_id\") \n",
    "lfc6.k.AvH <- lfcShrink(de6.k, contrast=c(\"treatment\", \"Add_Back\", \"High_Iron\"), type='ashr')\n",
    "lfc6.k.AvH <- lfc6.k.AvH %>% as.data.frame() %>% rownames_to_column(\"ko_id\")\n",
    "lfc13.k.AvH <- lfcShrink(de13.k,  contrast=c(\"treatment\", \"Add_Back\", \"High_Iron\"), type='ashr')\n",
    "lfc13.k.AvH <- lfc13.k.AvH %>% as.data.frame() %>% rownames_to_column(\"ko_id\") \n",
    "\n",
    "write.csv(lfc4.k.AvL, \"./de_res_files/lfc4.k.AvL.csv\", row.names=F)\n",
    "write.csv(lfc8.k.AvL, \"./de_res_files/lfc8.k.AvL.csv\", row.names=F)\n",
    "write.csv(lfc6.k.AvL, \"./de_res_files/lfc6.k.AvL.csv\", row.names=F)\n",
    "write.csv(lfc13.k.AvL, \"./de_res_files/lfc13.k.AvL.csv\", row.names=F)\n",
    "write.csv(lfc8.k.HvL, \"./de_res_files/lfc8.k.HvL.csv\", row.names=F)\n",
    "write.csv(lfc6.k.HvL, \"./de_res_files/lfc6.k.HvL.csv\", row.names=F)\n",
    "write.csv(lfc13.k.HvL, \"./de_res_files/lfc13.k.HvL.csv\", row.names=F)\n",
    "write.csv(lfc8.k.AvH, \"./de_res_files/lfc8.k.AvH.csv\", row.names=F)\n",
    "write.csv(lfc6.k.AvH, \"./de_res_files/lfc6.k.AvH.csv\", row.names=F)\n",
    "write.csv(lfc13.k.AvH, \"./de_res_files/lfc13.k.AvH.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdca0def-7132-4560-8259-86aa91f206ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(ko_id)`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ko_id</th><th scope=col>baseMean</th><th scope=col>log2FoldChange</th><th scope=col>lfcSE</th><th scope=col>pvalue</th><th scope=col>padj</th><th scope=col>symbol</th><th scope=col>name</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>K00525</td><td>1073.92643</td><td>-3.904022</td><td>0.2805200</td><td>8.315263e-46</td><td>1.930804e-42</td><td> E1.17.4.1A, nrdA, nrdE</td><td> ribonucleoside-diphosphate reductase alpha chain [EC:1.17.4.1]</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>K10734</td><td>  25.89301</td><td>-3.212495</td><td>0.5927836</td><td>1.303292e-09</td><td>1.061840e-07</td><td> GINS3                 </td><td> GINS complex subunit 3                                        </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>K10808</td><td> 501.63986</td><td>-3.196746</td><td>0.2288487</td><td>1.401861e-45</td><td>2.170081e-42</td><td> RRM2                  </td><td> ribonucleoside-diphosphate reductase subunit M2 [EC:1.17.4.1] </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>K18710</td><td>  22.68003</td><td>-3.160268</td><td>0.8150535</td><td>4.954375e-07</td><td>2.130381e-05</td><td> SLBP                  </td><td> histone RNA hairpin-binding protein                           </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>K22156</td><td>  56.82509</td><td>-3.085140</td><td>0.4034052</td><td>9.545449e-16</td><td>1.528588e-13</td><td> JADE3                 </td><td> protein Jade-3                                                </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>K14291</td><td>  83.10115</td><td>-3.078023</td><td>0.3364991</td><td>3.207594e-21</td><td>8.762392e-19</td><td> PHAX                  </td><td> phosphorylated adapter RNA export protein                     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 8\n",
       "\\begin{tabular}{r|llllllll}\n",
       "  & ko\\_id & baseMean & log2FoldChange & lfcSE & pvalue & padj & symbol & name\\\\\n",
       "  & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & K00525 & 1073.92643 & -3.904022 & 0.2805200 & 8.315263e-46 & 1.930804e-42 &  E1.17.4.1A, nrdA, nrdE &  ribonucleoside-diphosphate reductase alpha chain {[}EC:1.17.4.1{]}\\\\\n",
       "\t2 & K10734 &   25.89301 & -3.212495 & 0.5927836 & 1.303292e-09 & 1.061840e-07 &  GINS3                  &  GINS complex subunit 3                                        \\\\\n",
       "\t3 & K10808 &  501.63986 & -3.196746 & 0.2288487 & 1.401861e-45 & 2.170081e-42 &  RRM2                   &  ribonucleoside-diphosphate reductase subunit M2 {[}EC:1.17.4.1{]} \\\\\n",
       "\t4 & K18710 &   22.68003 & -3.160268 & 0.8150535 & 4.954375e-07 & 2.130381e-05 &  SLBP                   &  histone RNA hairpin-binding protein                           \\\\\n",
       "\t5 & K22156 &   56.82509 & -3.085140 & 0.4034052 & 9.545449e-16 & 1.528588e-13 &  JADE3                  &  protein Jade-3                                                \\\\\n",
       "\t6 & K14291 &   83.10115 & -3.078023 & 0.3364991 & 3.207594e-21 & 8.762392e-19 &  PHAX                   &  phosphorylated adapter RNA export protein                     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 8\n",
       "\n",
       "| <!--/--> | ko_id &lt;chr&gt; | baseMean &lt;dbl&gt; | log2FoldChange &lt;dbl&gt; | lfcSE &lt;dbl&gt; | pvalue &lt;dbl&gt; | padj &lt;dbl&gt; | symbol &lt;chr&gt; | name &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | K00525 | 1073.92643 | -3.904022 | 0.2805200 | 8.315263e-46 | 1.930804e-42 |  E1.17.4.1A, nrdA, nrdE |  ribonucleoside-diphosphate reductase alpha chain [EC:1.17.4.1] |\n",
       "| 2 | K10734 |   25.89301 | -3.212495 | 0.5927836 | 1.303292e-09 | 1.061840e-07 |  GINS3                  |  GINS complex subunit 3                                         |\n",
       "| 3 | K10808 |  501.63986 | -3.196746 | 0.2288487 | 1.401861e-45 | 2.170081e-42 |  RRM2                   |  ribonucleoside-diphosphate reductase subunit M2 [EC:1.17.4.1]  |\n",
       "| 4 | K18710 |   22.68003 | -3.160268 | 0.8150535 | 4.954375e-07 | 2.130381e-05 |  SLBP                   |  histone RNA hairpin-binding protein                            |\n",
       "| 5 | K22156 |   56.82509 | -3.085140 | 0.4034052 | 9.545449e-16 | 1.528588e-13 |  JADE3                  |  protein Jade-3                                                 |\n",
       "| 6 | K14291 |   83.10115 | -3.078023 | 0.3364991 | 3.207594e-21 | 8.762392e-19 |  PHAX                   |  phosphorylated adapter RNA export protein                      |\n",
       "\n"
      ],
      "text/plain": [
       "  ko_id  baseMean   log2FoldChange lfcSE     pvalue       padj        \n",
       "1 K00525 1073.92643 -3.904022      0.2805200 8.315263e-46 1.930804e-42\n",
       "2 K10734   25.89301 -3.212495      0.5927836 1.303292e-09 1.061840e-07\n",
       "3 K10808  501.63986 -3.196746      0.2288487 1.401861e-45 2.170081e-42\n",
       "4 K18710   22.68003 -3.160268      0.8150535 4.954375e-07 2.130381e-05\n",
       "5 K22156   56.82509 -3.085140      0.4034052 9.545449e-16 1.528588e-13\n",
       "6 K14291   83.10115 -3.078023      0.3364991 3.207594e-21 8.762392e-19\n",
       "  symbol                 \n",
       "1  E1.17.4.1A, nrdA, nrdE\n",
       "2  GINS3                 \n",
       "3  RRM2                  \n",
       "4  SLBP                  \n",
       "5  JADE3                 \n",
       "6  PHAX                  \n",
       "  name                                                           \n",
       "1  ribonucleoside-diphosphate reductase alpha chain [EC:1.17.4.1]\n",
       "2  GINS complex subunit 3                                        \n",
       "3  ribonucleoside-diphosphate reductase subunit M2 [EC:1.17.4.1] \n",
       "4  histone RNA hairpin-binding protein                           \n",
       "5  protein Jade-3                                                \n",
       "6  phosphorylated adapter RNA export protein                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranked4.AvL = lfc4.k.AvL[order(abs(lfc4.k.AvL$log2FoldChange), decreasing=TRUE),]\n",
    "ranked4.AvL = left_join(ranked4.AvL, ko.def)\n",
    "\n",
    "\n",
    "ranked8.AvL = lfc8.k.AvL[order(abs(lfc8.k.AvL$log2FoldChange), decreasing=TRUE),]\n",
    "ranked8.AvL = left_join(ranked8.AvL, ko.def)\n",
    "\n",
    "ranked8.HvL = lfc8.k.HvL[order(abs(lfc8.k.HvL$log2FoldChange), decreasing=TRUE),]\n",
    "ranked8.HvL = left_join(ranked8.HvL, ko.def)\n",
    "\n",
    "ranked8.AvH = lfc8.k.AvH[order(abs(lfc8.k.AvH$log2FoldChange), decreasing=TRUE),]\n",
    "ranked8.AvH = left_join(ranked8.AvH, ko.def)\n",
    "\n",
    "\n",
    "ranked6.AvL = lfc6.k.AvL[order(abs(lfc6.k.AvL$log2FoldChange), decreasing=TRUE),]\n",
    "ranked6.AvL = left_join(ranked6.AvL, ko.def)\n",
    "\n",
    "ranked6.HvL = lfc6.k.HvL[order(abs(lfc6.k.HvL$log2FoldChange), decreasing=TRUE),]\n",
    "ranked6.HvL = left_join(ranked6.HvL, ko.def)\n",
    "\n",
    "ranked6.AvH = lfc6.k.AvH[order(abs(lfc6.k.AvH$log2FoldChange), decreasing=TRUE),]\n",
    "ranked6.AvH = left_join(ranked6.AvH, ko.def)\n",
    "\n",
    "\n",
    "ranked13.AvL = lfc13.k.AvL[order(abs(lfc13.k.AvL$log2FoldChange), decreasing=TRUE),]\n",
    "ranked13.AvL = left_join(ranked13.AvL, ko.def)\n",
    "\n",
    "ranked13.HvL = lfc13.k.HvL[order(abs(lfc13.k.HvL$log2FoldChange), decreasing=TRUE),]\n",
    "ranked13.HvL = left_join(ranked13.HvL, ko.def)\n",
    "\n",
    "ranked13.AvH = lfc13.k.AvH[order(abs(lfc13.k.AvH$log2FoldChange), decreasing=TRUE),]\n",
    "ranked13.AvH = left_join(ranked13.AvH, ko.def)\n",
    "\n",
    "head(ranked13.AvH)\n",
    "write.csv(ranked4.AvL, \"./de_res_files/ranked4.AvL.csv\", row.names=F)\n",
    "write.csv(ranked8.AvL, \"./de_res_files/ranked8.AvL.csv\", row.names=F)\n",
    "write.csv(ranked6.AvL, \"./de_res_files/ranked6.AvL.csv\", row.names=F)\n",
    "write.csv(ranked13.AvL, \"./de_res_files/ranked13.AvL.csv\", row.names=F)\n",
    "write.csv(ranked8.AvH, \"./de_res_files/ranked8.AvH.csv\", row.names=F)\n",
    "write.csv(ranked6.AvH, \"./de_res_files/ranked6.AvH.csv\", row.names=F)\n",
    "write.csv(ranked13.AvH, \"./de_res_files/ranked13.AvH.csv\", row.names=F)\n",
    "write.csv(ranked8.HvL, \"./de_res_files/ranked8.HvL.csv\", row.names=F)\n",
    "write.csv(ranked6.HvL, \"./de_res_files/ranked6.HvL.csv\", row.names=F)\n",
    "write.csv(ranked13.HvL, \"./de_res_files/ranked13.HvL.csv\", row.names=F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
